#use the remaining 70% of the data for training and testing the models
trainingDataset <- NetflixTitles[validation_index,]
#Summarize data
#dimension of the dataset
dim(trainingDataset)
summary(trainingDataset)
#list types for each attribute
sapply(trainingDataset, class)
head(trainingDataset, n = 10)
#for each column, sums up all the empty values
colSums(is.na(trainingDataset))
trainingDataset$rating[trainingDataset$rating == "G" | trainingDataset$rating == "PG" | trainingDataset$rating == "TV-G" | trainingDataset$rating == "TV-PG" |
trainingDataset$rating == "TV-Y" | trainingDataset$rating == "TV-Y7" | trainingDataset$rating == "TV-Y7-FV"] <- "AP"
trainingDataset$rating[trainingDataset$rating == "NC-17" | trainingDataset$rating == "NR" | trainingDataset$rating == "R" | trainingDataset$rating == "TV-MA" |
trainingDataset$rating == "UR"] <- "18"
trainingDataset$rating[trainingDataset$rating == "PG-13"] <- "12"
trainingDataset$rating[trainingDataset$rating == "TV-14"] <- "15"
# convert data types
trainingDataset[,4] <- as.numeric(trainingDataset[,4])
trainingDataset[, 'date_added'] <- as.Date(trainingDataset[, 'date_added'], format = '%B %d, %Y')
trainingDataset[, 'type'] <- factor(trainingDataset[, 'type'], labels = c("Movie", "TV Show"))
trainingDataset[, 'rating'] <- factor(trainingDataset[, 'rating'])
#list types for each attribute
sapply(trainingDataset, class)
#Removing empty values created after conversion
colSums(is.na(trainingDataset))
trainingDataset <- trainingDataset[complete.cases(trainingDataset),]
str(trainingDataset)
#Using cross validation with Accuracy metric
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# GLMNET
set.seed(7)
fit.glmnet <- train(rating~type+release_year, data=trainingDataset, method="glmnet", metric=metric, trControl=control)
# CART
set.seed(7)
fit.cart <- train(rating~type+release_year, data = trainingDataset, method = "rpart", metric = metric, trControl=control)
# kNN
set.seed(7)
fit.knn <- train(rating~type+release_year, data = trainingDataset, method = "knn", metric = metric, trControl=control)
#Support Vector Machine
set.seed(7)
fit.svm <- train(rating~type+release_year, data = trainingDataset, method = "svmRadial", metric = metric, trControl=control)
#Linear Discriminant Analysis
set.seed(7)
fit.lda <- train(rating~type+release_year, data = trainingDataset, method = "lda", metric = metric, trControl=control)
results <- resamples(list(GLMNET=fit.glmnet, CART=fit.cart, KNN=fit.knn, SVM=fit.svm, LDA = fit.lda))
summary(ensemble_results)
summary(results)
validationDataset$rating[validationDataset$rating == "G" | validationDataset$rating == "PG" | validationDataset$rating == "TV-G" | validationDataset$rating == "TV-PG" |
validationDataset$rating == "TV-Y" | validationDataset$rating == "TV-Y7" | validationDataset$rating == "TV-Y7-FV"] <- "AP"
validationDataset$rating[validationDataset$rating == "NC-17" | validationDataset$rating == "NR" | validationDataset$rating == "R" | validationDataset$rating == "TV-MA" |
validationDataset$rating == "UR"] <- "18"
validationDataset$rating[validationDataset$rating == "PG-13"] <- "12"
validationDataset$rating[validationDataset$rating == "TV-14"] <- "15"
validationDataset[,4] <- as.numeric(validationDataset[,4])
validationDataset[, 'date_added'] <- as.Date(validationDataset[, 'date_added'], format = '%B %d, %Y')
validationDataset[, 'type'] <- factor(validationDataset[, 'type'], labels = c("Movie", "TV Show"))
validationDataset[, 'rating'] <- factor(validationDataset[, 'rating'])
predictions <- predict(fit.lda, trainingDataset[c(1, 4:5)])
print(predictions)
confusionMatrix(predictions, validationDataset$type)
confusionMatrix(predictions, validationDataset$rating)
predictions <- predict(fit.lda, trainingDataset[,c(1, 4:5)])
print(predictions)
confusionMatrix(predictions, validationDataset$rating)
confusionMatrix(predictions, validationDataset$rating~type+release_year)
predictions <- predict(fit.lda, trainingDataset$rating)
predictions <- predict(fit.lda, trainingDataset[,c(1, 4,5)])
confusionMatrix(predictions, validationDataset$rating)
confusionMatrix(predictions, validationDataset$type)
View(trainingDataset)
predictions <- predict(fit.lda, validationDataset[,c(1, 4,5)])
confusionMatrix(predictions, validationDataset$rating)
#Netflix Titles dataset
#load libraries
library(mlbench)
library(caret)
library(corrplot)
library(ltm)
library(klaR)
#define filename
filename <- "netflix_titles.csv"
#load CSV file from the local directory
NetflixTitles <- read.csv(filename, header = FALSE, na.strings = c("", "NA"))
#preview the first 5 rows
head(NetflixTitles)
#dimension of the dataset
dim(NetflixTitles)
#summarize attribute distribution for the entire dataset
summary(NetflixTitles)
#for each column, sums up all the empty values
colSums(is.na(NetflixTitles))
#Removing columns with NA values and description column because is no use
NetflixTitles <- NetflixTitles[, -c(1, 4:6, 11:12)]
#Removing rows with NA values
NetflixTitles <- NetflixTitles[complete.cases(NetflixTitles),]
#Renaming columns
names(NetflixTitles)[names(NetflixTitles) == "V2"] <- "type"
names(NetflixTitles)[names(NetflixTitles) == "V3"] <- "title"
names(NetflixTitles)[names(NetflixTitles) == "V7"] <- "date_added"
names(NetflixTitles)[names(NetflixTitles) == "V8"] <- "release_year"
names(NetflixTitles)[names(NetflixTitles) == "V9"] <- "rating"
names(NetflixTitles)[names(NetflixTitles) == "V10"] <- "duration"
#Removing unnecessary row(first row)
NetflixTitles <- NetflixTitles[-1,]
#Searching and removing duplicates
NetflixTitles[duplicated(NetflixTitles[, 1:6]), ]
NetflixTitles <- NetflixTitles[!duplicated(NetflixTitles[, 1:6]), ]
#Split out validation dataset
# create list of 70% of the rows in the original dataset we can use for training
set.seed(7)
validation_index <- caret::createDataPartition(NetflixTitles$type, p = 0.7, list = FALSE)
#select 30% of the data for validation
validationDataset <- NetflixTitles[-validation_index,]
#use the remaining 70% of the data for training and testing the models
trainingDataset <- NetflixTitles[validation_index,]
#Summarize data
#dimension of the dataset
dim(trainingDataset)
summary(trainingDataset)
#list types for each attribute
sapply(trainingDataset, class)
head(trainingDataset, n = 10)
#for each column, sums up all the empty values
colSums(is.na(trainingDataset))
trainingDataset$rating[trainingDataset$rating == "G" | trainingDataset$rating == "PG" | trainingDataset$rating == "TV-G" | trainingDataset$rating == "TV-PG" |
trainingDataset$rating == "TV-Y" | trainingDataset$rating == "TV-Y7" | trainingDataset$rating == "TV-Y7-FV"] <- "AP"
trainingDataset$rating[trainingDataset$rating == "NC-17" | trainingDataset$rating == "NR" | trainingDataset$rating == "R" | trainingDataset$rating == "TV-MA" |
trainingDataset$rating == "UR"] <- "Adult"
trainingDataset$rating[trainingDataset$rating == "PG-13"] <- "AP"
trainingDataset$rating[trainingDataset$rating == "TV-14"] <- "Adult"
# convert data types
trainingDataset[,4] <- as.numeric(trainingDataset[,4])
trainingDataset[, 'date_added'] <- as.Date(trainingDataset[, 'date_added'], format = '%B %d, %Y')
trainingDataset[, 'type'] <- factor(trainingDataset[, 'type'], labels = c("Movie", "TV Show"))
trainingDataset[, 'rating'] <- factor(trainingDataset[, 'rating'])
#list types for each attribute
sapply(trainingDataset, class)
#Removing empty values created after conversion
colSums(is.na(trainingDataset))
trainingDataset <- trainingDataset[complete.cases(trainingDataset),]
colSums(is.na(trainingDataset))
biserial.cor(trainingDataset$release_year, trainingDataset$type)
cor(trainingDataset$release_year, as.numeric(trainingDataset$date_added, format = "%Y-%m-%d"))
ggplot(trainingDataset, aes(x=type, fill = type)) + geom_bar(show.legend=T)
ggplot(trainingDataset, aes(x=rating, fill = rating)) + geom_bar(show.legend=T)
ggplot(trainingDataset, aes(rating, fill = type)) + geom_bar(show.legend=T)
ggplot(trainingDataset, aes(rating, release_year, fill = rating)) + geom_boxplot() + theme_grey()
ggplot(trainingDataset, aes(x="", fill=rating)) + geom_bar(position="fill", width=1) + coord_polar("y") + theme_void()
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
set.seed(7)
fit.glmnet <- train(rating~type+release_year, data=trainingDataset, method="glmnet", metric=metric, trControl=control)
# CART
set.seed(7)
fit.cart <- train(rating~type+release_year, data = trainingDataset, method = "rpart", metric = metric, trControl=control)
# kNN(k-Nearest Neighbour)
set.seed(7)
fit.knn <- train(rating~type+release_year, data = trainingDataset, method = "knn", metric = metric, trControl=control)
#Support Vector Machine
set.seed(7)
fit.svm <- train(rating~type+release_year, data = trainingDataset, method = "svmRadial", metric = metric, trControl=control)
#Linear Discriminant Analysis
set.seed(7)
fit.lda <- train(rating~type+release_year, data = trainingDataset, method = "lda", metric = metric, trControl=control)
results <- resamples(list(GLMNET=fit.glmnet, CART=fit.cart, KNN=fit.knn, SVM=fit.svm, LDA = fit.lda))
summary(results)
dotplot(results)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# Random Forest
set.seed(7)
fit.rf <- train(rating~type+release_year, data = trainingDataset, method="rf", metric=metric, trControl=control)
# Stochastic Gradient Boosting
set.seed(7)
fit.gbm <- train(rating~type+release_year, data = trainingDataset, method="gbm", metric=metric, trControl=control, verbose=FALSE)
# Compare algorithms
ensemble_results <- resamples(list(RF=fit.rf, GBM=fit.gbm))
summary(ensemble_results)
validationDataset$rating[validationDataset$rating == "G" | validationDataset$rating == "PG" | validationDataset$rating == "TV-G" | validationDataset$rating == "TV-PG" |
validationDataset$rating == "TV-Y" | validationDataset$rating == "TV-Y7" | validationDataset$rating == "TV-Y7-FV"] <- "AP"
validationDataset$rating[validationDataset$rating == "NC-17" | validationDataset$rating == "NR" | validationDataset$rating == "R" | validationDataset$rating == "TV-MA" |
validationDataset$rating == "UR"] <- "Adult"
validationDataset$rating[validationDataset$rating == "PG-13"] <- "AP"
validationDataset$rating[validationDataset$rating == "TV-14"] <- "Adult"
# convert data types
validationDataset[,4] <- as.numeric(validationDataset[,4])
validationDataset[, 'date_added'] <- as.Date(validationDataset[, 'date_added'], format = '%B %d, %Y')
validationDataset[, 'type'] <- factor(validationDataset[, 'type'], labels = c("Movie", "TV Show"))
validationDataset[, 'rating'] <- factor(validationDataset[, 'rating'])
predictions <- predict(fit.lda, validationDataset[, c(1,4,5)])
confusionMatrix(predictions, validationDataset$rating)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# GLMNET
set.seed(7)
fit.glmnet <- train(type~rating+release_year, data=trainingDataset, method="glmnet", metric=metric, trControl=control)
# CART
set.seed(7)
fit.cart <- train(type~rating+release_year, data = trainingDataset, method = "rpart", metric = metric, trControl=control)
# kNN(k-Nearest Neighbour)
set.seed(7)
fit.knn <- train(type~rating+release_year, data = trainingDataset, method = "knn", metric = metric, trControl=control)
#Support Vector Machine
set.seed(7)
fit.svm <- train(type~rating+release_year, data = trainingDataset, method = "svmRadial", metric = metric, trControl=control)
#Linear Discriminant Analysis
set.seed(7)
fit.lda <- train(type~rating+release_year, data = trainingDataset, method = "lda", metric = metric, trControl=control)
results <- resamples(list(GLMNET=fit.glmnet, CART=fit.cart, KNN=fit.knn, SVM=fit.svm, LDA = fit.lda))
summary(results)
#load libraries
library(mlbench)
library(caret)
library(corrplot)
library(ltm)
library(klaR)
#define filename
filename <- "netflix_titles.csv"
#load CSV file from the local directory
NetflixTitles <- read.csv(filename, header = FALSE, na.strings = c("", "NA"))
#preview the first 5 rows
head(NetflixTitles)
#dimension of the dataset
dim(NetflixTitles)
#summarize attribute distribution for the entire dataset
summary(NetflixTitles)
#for each column, sums up all the empty values
colSums(is.na(NetflixTitles))
#Removing columns with NA values and description column because is no use
NetflixTitles <- NetflixTitles[, -c(1, 4:6, 11:12)]
#Removing rows with NA values
NetflixTitles <- NetflixTitles[complete.cases(NetflixTitles),]
#Renaming columns
names(NetflixTitles)[names(NetflixTitles) == "V2"] <- "type"
names(NetflixTitles)[names(NetflixTitles) == "V3"] <- "title"
names(NetflixTitles)[names(NetflixTitles) == "V7"] <- "date_added"
names(NetflixTitles)[names(NetflixTitles) == "V8"] <- "release_year"
names(NetflixTitles)[names(NetflixTitles) == "V9"] <- "rating"
names(NetflixTitles)[names(NetflixTitles) == "V10"] <- "duration"
NetflixTitles$rating[NetflixTitles$rating == "G" | NetflixTitles$rating == "PG" | NetflixTitles$rating == "TV-G" | NetflixTitles$rating == "TV-PG" |
NetflixTitles$rating == "TV-Y" | NetflixTitles$rating == "TV-Y7" | NetflixTitles$rating == "TV-Y7-FV"] <- "AP"
NetflixTitles$rating[NetflixTitles$rating == "NC-17" | NetflixTitles$rating == "NR" | NetflixTitles$rating == "R" | NetflixTitles$rating == "TV-MA" |
NetflixTitles$rating == "UR"] <- "Adult"
NetflixTitles$rating[NetflixTitles$rating == "PG-13"] <- "AP"
NetflixTitles$rating[NetflixTitles$rating == "TV-14"] <- "Adult"
#Removing unnecessary row(first row)
NetflixTitles <- NetflixTitles[-1,]
#Searching and removing duplicates
NetflixTitles[duplicated(NetflixTitles[, 1:6]), ]
NetflixTitles <- NetflixTitles[!duplicated(NetflixTitles[, 1:6]), ]
#Split out validation dataset
# create list of 70% of the rows in the original dataset we can use for training
set.seed(7)
validation_index <- caret::createDataPartition(NetflixTitles$rating, p = 0.7, list = FALSE)
#select 30% of the data for validation
validationDataset <- NetflixTitles[-validation_index,]
#use the remaining 70% of the data for training and testing the models
trainingDataset <- NetflixTitles[validation_index,]
#Summarize data
#dimension of the dataset
dim(trainingDataset)
summary(trainingDataset)
#list types for each attribute
sapply(trainingDataset, class)
head(trainingDataset, n = 10)
#for each column, sums up all the empty values
colSums(is.na(trainingDataset))
trainingDataset[,4] <- as.numeric(trainingDataset[,4])
trainingDataset[, 'date_added'] <- as.Date(trainingDataset[, 'date_added'], format = '%B %d, %Y')
trainingDataset[, 'type'] <- factor(trainingDataset[, 'type'], labels = c("Movie", "TV Show"))
trainingDataset[, 'rating'] <- factor(trainingDataset[, 'rating'], labels = c("Adult", "AP"))
colSums(is.na(trainingDataset))
trainingDataset <- trainingDataset[complete.cases(trainingDataset),]
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# GLMNET
set.seed(7)
fit.glmnet <- train(rating~type+release_year, data=trainingDataset, method="glmnet", metric=metric, trControl=control)
# CART
set.seed(7)
fit.cart <- train(rating~type+release_year, data = trainingDataset, method = "rpart", metric = metric, trControl=control)
# kNN(k-Nearest Neighbour)
set.seed(7)
fit.knn <- train(rating~type+release_year, data = trainingDataset, method = "knn", metric = metric, trControl=control)
#Support Vector Machine
set.seed(7)
fit.svm <- train(rating~type+release_year, data = trainingDataset, method = "svmRadial", metric = metric, trControl=control)
#Linear Discriminant Analysis
set.seed(7)
fit.lda <- train(rating~type+release_year, data = trainingDataset, method = "lda", metric = metric, trControl=control)
results <- resamples(list(GLMNET=fit.glmnet, CART=fit.cart, KNN=fit.knn, SVM=fit.svm, LDA = fit.lda))
summary(results)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# Random Forest
set.seed(7)
fit.rf <- train(rating~type+release_year, data = trainingDataset, method="rf", metric=metric, trControl=control)
# Stochastic Gradient Boosting
set.seed(7)
fit.gbm <- train(rating~type+release_year, data = trainingDataset, method="gbm", metric=metric, trControl=control, verbose=FALSE)
# Compare algorithms
ensemble_results <- resamples(list(RF=fit.rf, GBM=fit.gbm))
summary(ensemble_results)
print(fit.rf)
validationDataset[,4] <- as.numeric(validationDataset[,4])
validationDataset[, 'date_added'] <- as.Date(validationDataset[, 'date_added'], format = '%B %d, %Y')
validationDataset[, 'type'] <- factor(validationDataset[, 'type'], labels = c("Movie", "TV Show"))
validationDataset[, 'rating'] <- factor(validationDataset[, 'rating'], labels = c("Adult", "AP"))
predictions <- predict(fit.rf, validationDataset[, c(1,4,5)])
print(predictions)
confusionMatrix(predictions, validationDataset$rating)
covid19 <- read.csv("COVID19_line_list_data.csv", stringsAsFactors = F)
#loading all required libraries
library(dplyr)
library(ggplot2)
library(Boruta)
library(tidyverse)
library(stringr)
dim(covid19)
#to view the top portion of dataset
head(covid19)
#cheking the structure of datset
str(covid19)
#checking various features of the column symptom
table(covid19$symptom)
#making new columns based on symptoms features
covid19$fever <- str_detect(covid19$symptom, 'fever|cough|headache|sore throat|sputum|malaise|coughing|muscle aches|high fever|physical discomfort')
covid19$gastric <- str_detect(covid19$symptom,'vomiting|diarrhea|pneumonia|abdominal pain')
#selecting the required variables in the dataset
covid19 <- covid19 %>%
select(reporting.date, country, gender, age, death, fever, gastric, symptom)
#converting death variable into binomial (numeric)
covid19$death <- ifelse(covid19$death == '0', 0, 1)
#converting date format
covid19$reporting.date <- as.Date(covid19$reporting.date, "%m/%d/%Y")
#factorizing other categorical variables
covid19$country <- factor(covid19$country)
covid19$gender <- factor(covid19$gender)
covid19$death <- factor(covid19$death, label = c('no','yes'))
covid19$fever <- factor(covid19$fever, label = c('no','yes'))
covid19$gastric <- factor(covid19$gastric, label = c('no','yes'))
head(covid19)
###!!!!!
str(covid19)
summary(covid19)
#removing missing values by mean and Not detected
mean_age <- mean(covid19$age, na.rm=T)
covid19$age[which(is.na(covid19$age))] <- mean_age
covid19$gender1 <- as.character(covid19$gender)
covid19$gender1[which(is.na(covid19$gender1))] <- 'Not detected' ##null
covid19$gender <- as.factor(covid19$gender1)
covid19 <- select(covid19, -gender1)
table(is.na(covid19))
tail(covid19)
which(is.na(covid19$reporting.date))
covid19[262,]
covid19 <- covid19[-262,]
covid19 <- select(covid19, -symptom)
#rounding the age value
covid19$age <- round(covid19$age, 0)
library(caret)
#cross validation for various models
control <- trainControl(method='cv', number=10)
metric <- "Accuracy"
#splitting dataset into training and test data
library(caTools)
set.seed(1234)
split <- sample.split(covid19$death, SplitRatio = 0.75)
train_split <- subset(covid19, split==T)
test_split <- subset(covid19, split==F)
#various models
#Linear Discriminant Analysis
set.seed(1234)
fit.lda <- train(death~gender+age, data=covid19, method='lda', metric=metric, trcontrol=control)
#Support Vector Machine
set.seed(1234)
fit.svm <- train(death~gender+age, data=covid19, method='svmRadial', metric=metric, trcontrol=control)
#random forest
set.seed(1234)
fit.rf <- train(death~gender+age, data=covid19, method='rf', metric=metric, trcontrol=control)
#listing all the results to check accuracy
results <- resamples(list(lda=fit.lda, svm=fit.svm, rf=fit.rf))
summary(results)
print(fit.rf)
predictions <- predict(fit.rf, test_split[3:5])
#Confusion Matrix
confusionMatrix(predictions, test_split$death)
#Netflix Titles dataset
#load libraries
library(mlbench)
library(caret)
library(corrplot)
library(ltm)
library(klaR)
#define filename
filename <- "netflix_titles.csv"
#load CSV file from the local directory
NetflixTitles <- read.csv(filename, header = FALSE, na.strings = c("", "NA"))
#preview the first 5 rows
head(NetflixTitles)
#dimension of the dataset
dim(NetflixTitles)
#summarize attribute distribution for the entire dataset
summary(NetflixTitles)
#for each column, sums up all the empty values
colSums(is.na(NetflixTitles))
#Removing columns with NA values and description column because is no use
NetflixTitles <- NetflixTitles[, -c(1, 4:6, 11:12)]
#Removing rows with NA values
NetflixTitles <- NetflixTitles[complete.cases(NetflixTitles),]
#Renaming columns
names(NetflixTitles)[names(NetflixTitles) == "V2"] <- "type"
names(NetflixTitles)[names(NetflixTitles) == "V3"] <- "title"
names(NetflixTitles)[names(NetflixTitles) == "V7"] <- "date_added"
names(NetflixTitles)[names(NetflixTitles) == "V8"] <- "release_year"
names(NetflixTitles)[names(NetflixTitles) == "V9"] <- "rating"
names(NetflixTitles)[names(NetflixTitles) == "V10"] <- "duration"
NetflixTitles$rating[NetflixTitles$rating == "G" | NetflixTitles$rating == "PG" | NetflixTitles$rating == "TV-G" | NetflixTitles$rating == "TV-PG" |
NetflixTitles$rating == "TV-Y" | NetflixTitles$rating == "TV-Y7" | NetflixTitles$rating == "TV-Y7-FV"
| NetflixTitles$rating == "PG-13"] <- "AP"
NetflixTitles$rating[NetflixTitles$rating == "NC-17" | NetflixTitles$rating == "NR" | NetflixTitles$rating == "R" | NetflixTitles$rating == "TV-MA" |
NetflixTitles$rating == "UR" | NetflixTitles$rating == "TV-14"] <- "Adult"
#Removing unnecessary row(first row)
NetflixTitles <- NetflixTitles[-1,]
#Searching and removing duplicates
NetflixTitles[duplicated(NetflixTitles[, 1:6]), ]
NetflixTitles <- NetflixTitles[!duplicated(NetflixTitles[, 1:6]), ]
#Split out validation dataset
# create list of 70% of the rows in the original dataset we can use for training
set.seed(7)
validation_index <- caret::createDataPartition(NetflixTitles$rating, p = 0.7, list = FALSE)
#select 30% of the data for validation
validationDataset <- NetflixTitles[-validation_index,]
#use the remaining 70% of the data for training and testing the models
trainingDataset <- NetflixTitles[validation_index,]
#Summarize data
#dimension of the dataset
dim(trainingDataset)
summary(trainingDataset)
#list types for each attribute
sapply(trainingDataset, class)
head(trainingDataset, n = 10)
#for each column, sums up all the empty values
colSums(is.na(trainingDataset))
# convert data types
trainingDataset[,4] <- as.numeric(trainingDataset[,4])
trainingDataset[, 'date_added'] <- as.Date(trainingDataset[, 'date_added'], format = '%B %d, %Y')
trainingDataset[, 'type'] <- factor(trainingDataset[, 'type'], labels = c("Movie", "TV Show"))
trainingDataset[, 'rating'] <- factor(trainingDataset[, 'rating'], labels = c("Adult", "AP"))
#list types for each attribute
sapply(trainingDataset, class)
#Removing empty values created after conversion
colSums(is.na(trainingDataset))
trainingDataset <- trainingDataset[complete.cases(trainingDataset),]
str(trainingDataset)
#Using cross validation with Accuracy metric
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# GLMNET
set.seed(7)
fit.glmnet <- train(rating~type+release_year, data=trainingDataset, method="glmnet", metric=metric, trControl=control)
# CART
set.seed(7)
fit.cart <- train(rating~type+release_year, data = trainingDataset, method = "rpart", metric = metric, trControl=control)
# kNN(k-Nearest Neighbour)
set.seed(7)
fit.knn <- train(rating~type+release_year, data = trainingDataset, method = "knn", metric = metric, trControl=control)
#Support Vector Machine
set.seed(7)
fit.svm <- train(rating~type+release_year, data = trainingDataset, method = "svmRadial", metric = metric, trControl=control)
#Linear Discriminant Analysis
set.seed(7)
fit.lda <- train(rating~type+release_year, data = trainingDataset, method = "lda", metric = metric, trControl=control)
results <- resamples(list(GLMNET=fit.glmnet, CART=fit.cart, KNN=fit.knn, SVM=fit.svm, LDA = fit.lda))
summary(results)
dotplot(results)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
metric <- "Accuracy"
# Random Forest
set.seed(7)
fit.rf <- train(rating~type+release_year, data = trainingDataset, method="rf", metric=metric, trControl=control)
# Stochastic Gradient Boosting
set.seed(7)
fit.gbm <- train(rating~type+release_year, data = trainingDataset, method="gbm", metric=metric, trControl=control, verbose=FALSE)
# Compare algorithms
ensemble_results <- resamples(list(RF=fit.rf, GBM=fit.gbm))
summary(ensemble_results)
dotplot(ensemble_results)
print(fit.rf)
validationDataset[,4] <- as.numeric(validationDataset[,4])
validationDataset[, 'date_added'] <- as.Date(validationDataset[, 'date_added'], format = '%B %d, %Y')
validationDataset[, 'type'] <- factor(validationDataset[, 'type'], labels = c("Movie", "TV Show"))
validationDataset[, 'rating'] <- factor(validationDataset[, 'rating'], labels = c("Adult", "AP"))
predictions <- predict(fit.rf, validationDataset[, c(1,4,5)])
print(predictions)
confusionMatrix(predictions, validationDataset$rating)
saveRDS(fit.rf, "MyFinalModel.rds")
summary(results)
summary(ensemble_results)
library(mlbench)
library(caret)
library(corrplot)
library(ltm)
library(klaR)
results <- resamples(list(GLMNET=fit.glmnet, CART=fit.cart, KNN=fit.knn, SVM=fit.svm, LDA = fit.lda))
summary(results)
summary(ensemble_results)
predictions <- predict(fit.rf, validationDataset[, c(1,4,5)])
print(predictions)
confusionMatrix(predictions, validationDataset$rating)
